identical(vect,vect2)
vect["bar"]
vect[c("foo","bar")]
my_vector <- c(1:20)
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
matrix(1:20,4,5)
my_matrix2 <- matrix(1:20,4,5)
identical(my_matrix,my_matrix2)
patients <- C("Bill","Gina","Kelly","Sean")
patients <- c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients,my_matrix)
my_data
class(my_data)
cnames <- c("patient","age","weight","bp","rating","test")
colnames(my_data,cnames)
?colnames
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE==TRUE)==FALSE
6==7
6<7
10<=10
5!=7
!(5==7)
FALSE & FALSE
TRUE & c(TRUE,FALSE,FALSE)
TRUE && c(TRUE,FALSE,FALSE)
TRUE | c(TRUE,FALSE,FALSE)
TRUE || c(TRUE,FALSE,FALSE)
5>8||6!=8&&4>3.9
isTrue(6>4)
isTRUE(6>4)
identical('twins','twins')
xor(5==6,!FALSE)
ints <- sample(10)
ints
ints > 5
?wich
?which
which(ints >7)
any(ints < 0)
all(ints>0)
Sys.Date()
mean(c(2,4,5))
submit()
boring_function('My first function!')
boring_function
submit()
my_mean(c(4,5,10))
submit()
submit()
remainder(5)
remainder(11,5)
remainder(divisor=11,num=5)
remainder(4,div=2)
args(remainder)
submit()
evaluate(std,c(1.4,3.6,7.9,8.8))
evaluate(sd,c(1.4,3.6,7.9,8.8))
evaluate(function(x){x+1},6)
evaluate(function(x){x[1]},c(8,4,0))
evaluate(function(x){x[length(x)]},c(8,4,0))
?paste
paste("Programming","is","fun!")
submit()
telegram("hello")
submit()
submit()
submit()
submit()
mad_libs(place="NY",adjective="large",noun="donkey")
submit()
"I"%p%"love"%p%"R!"
head(flags)
dim(flags)
class(flags)
cls_list <-lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors,sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes,range)
sapply(flag_shapes,range)
shape_mat <-sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(flags,unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags,unique)
vapply(flags,unique,numeric(1))
ok()
sapply(flags,class)
vapply(f;ags,class,character(1))
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass,mean)
tapply(flags$population,flags$red,summary)
tapply(flags$population,flags$landmasses,summary)
tapply(flags$population,flags$landmass,summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6,4,replace=TRUE)
sample(1:6,4,replace=TRUE)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1),100,replace=TRUE,prob=c(0.3,0.7))
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=0.7)
flips2 <- rbinom(1,size=100,prob=0.7)
flips2 <- rbinom(n=100,size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,100,25)
?rpois
rpois(5,10)
my_pois <- replicate(100,rpois(5,10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(t1)
weekdays(d1)
weekdays(t1)
months(t1)
quarters(t2)
ts <- "October 17, 1986 08:24"
t3 <- "October 17, 1986 08:24"
strptime(t3,"%B %d, %y %H:%M")
strptime(t3,"%B %d, %Y %H:%M")
t4 <-strptime(t3,"%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time()-t1
difftime(Sys.time(),t1,units='days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$speed,y=cars$dist)
plot(x=cars$dist,y=cars$speed)
?plot
plot(x=cars$dist,y=cars$speed,xlab="Speed")
plot(x=cars$dist,y=cars$speed,ylab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed")
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance",xlab="Speed")
?plot
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance",xlab="Speed",main="My Plot")
plot(cars,main="My plot")
plot(cars,main="My Plot")
plot(cars,sub="My Plot Subtitle")
?par
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2)
load(mtcars)
data(mtcars)
?boxplot
boxplopt(mtcars,formula=mpg~cyl)
boxplot(mtcars,formula=mpg~cyl)
boxplot(formula = mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
install_packages(KernSmooth)
install.packages(KernSmooth)
install.packages(KernSmooth R)
install.packages(KernSmooth)
install.packages("KernSmooth")
library(KernSmooth)
cube <- function(x,n){x^3}
cube(3)
x <- 1:10
if(x>5){x <- 0}
f<-function(x){g<-function(y){y+z};z<-4;x+g(x)}
z<-10
f(3)
x<-5
y<-if(x<3){NA}else{10}
y
x<-matrix(c(-1,1),c(-1,1),2,2)
?matrix
a<-c(-1,1)
b<-c(-1,1)
m<-matrix(c(a,b),2,2)
m
a<-c(1,1)
b<-c(-1,-1)
m<-matrix(c(a,b),2,2)
m
solve(m)
?solve
test
test()
makeCacheMatrix <- function(x = matrix()) {
## @x: a square invertible matrix
## return: a list containing functions to
##              1. set the matrix
##              2. get the matrix
##              3. set the inverse
##              4. get the inverse
##         this list is used as the input to cacheSolve()
inv = NULL
set = function(y) {
# use `<<-` to assign a value to an object in an environment
# different from the current environment.
x <<- y
inv <<- NULL
}
get = function() x
setinv = function(inverse) inv <<- inverse
getinv = function() inv
list(set=set, get=get, setinv=setinv, getinv=getinv)
}
cacheSolve <- function(x, ...) {
## @x: output of makeCacheMatrix()
## return: inverse of the original matrix input to makeCacheMatrix()
inv = x$getinv()
# if the inverse has already been calculated
if (!is.null(inv)){
# get it from the cache and skips the computation.
message("getting cached data")
return(inv)
}
# otherwise, calculates the inverse
mat.data = x$get()
inv = solve(mat.data, ...)
# sets the value of the inverse in the cache via the setinv function.
x$setinv(inv)
return(inv)
}
test = function(mat){
## @mat: an invertible matrix
temp = makeCacheMatrix(mat)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
start.time = Sys.time()
cacheSolve(temp)
dur = Sys.time() - start.time
print(dur)
}
test()
mymatrice <- matrix(rnorm(100),10,10)
mymatrice
test(mymatrice)
test(mymatrice)
install.packages("devtools")
devtools::install_github("gmlang/ezplot")
library(ezplot)
plt = mk_boxplot(films)
title1 = "Annual Distribution of Budget from 1913 to 2014"
p = plt("year_cat", "budget", ylab="budget", main=title1)
print(p)
scale_axis(p, "y", use_comma=T)
scale_axis(p, "y", use_log=T)
scale_axis(p, "y", use_log10=T)
?ezplot
set.seed(1)
rpois(5,2)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="quizdata",method="curl")
quizcsv <- read.csv("quizdata")
colnames(quizcsv)
class(quizcsv)
millplus <- quizcsv$val == 24
millplus
?count
count(quizcsv, "val")
count(quizcsv, vars="val")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
count(quizcsv, vars="val")
count(quizcsv, vars="VAL")
myfes <- quizcsv$FES
myfes
?read.excel
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="quizxl.xlsx",method="curl")
library(xlsx)
?read.xlsx
library(xlxs)
install.packages("xlsx")
library(xlxs)
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
rowindex <- 18:23
colindex <- 7:15
dat <- read.xlsx("quizxl.xlsx",sheetIndex=1,colIndex=colindex,rowIndex=rowindex)
sum(dat$Zip*dat$Ext,na.rm=T)
library(xml)
library(XML)
install.package("XML")
install.packages("XML")
library(XML)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml",useInternal=TRUE)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata/data/restaurants.xml",useInternal=TRUE)
?xmlTreeParse
doc <- xmlTreeParse("http://d396qusza40orc.cloudfront.net/getdata/data/restaurants.xml",useInternal=TRUE)
names(doc)
names(rootNode)
rootNode <- xmlRoot(doc)
names(rootNode)
names(row)
xmlName(rootNode)
rootNode
node[@zipcode='21231']
node[zipcode='21231']
rootNode[[1]]
rootNode[[1][1]]
rootNode[[1]][[1]]
xpathSApply(rootNode,"//zipcode",xmlValue)
xpathSApply(rootNode,"//zipcode",xmlValue='21231')
?xpathSApply
zip <- xpathSApply(doc, "/response/row/row/zipcode", xmlValue)
sum(zip == "21231")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",destfile="idaho.csv",method="curl")
?fread
?fRead
install.packages(data.table)
install.packages("data.table")
libray(data.table)
library(data.table)
?fread
DT <- fread("idaho.csv")
head(DT)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time((mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)))
system.time(mean(DT$pwgtp15,by=DT$SEX))
mean(DT$pwgtp15,by=DT$SEX)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
str(BodyWeight)
Str(Diet)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
setwd("~/Downloads/DataProductsProject")
setwd("~/Downloads/StatisticalInferenceProject")
library(datasets)
library(ggplot2)
ggplot(data=ToothGrowth, aes(x=as.factor(dose), y=len, fill=supp)) +
geom_bar(stat="identity",) +
facet_grid(. ~ supp) +
xlab("Dose in miligrams") +
ylab("Tooth length") +
guides(fill=guide_legend(title="Supplement type"))
fit <- lm(len ~ dose + supp, data=ToothGrowth)
summary(fit)
confint(fit)
?confint
confint(fit, level=0.95)
cor(fit)
?cor
cor(fit, len, dose+supp)
cor(fit, len, dose)
summary(fit)
cor(ToothGrowth, len, dose+supp)
cor(ToothGrowth, len, supp)
cor(ToothGrowth, len)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
# plot the histogram of averages
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="green")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
setwd("~/Downloads/PracticalMachineLearningProject")
raw.validation <- read.pml("pml-testing.csv")
set.seed(13)
## Setup
library(caret)
library(dplyr)
library(randomForest)
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
install.packages("randomForest")
## Setup
library(caret)
library(dplyr)
library(randomForest)
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
## Download and load the data, cleaning up the data during load
download.file(trainurl, "./train.csv", method = "curl")
download.file(testurl, "./test.csv", method = "curl")
train <- read.csv("./train.csv", na.strings = c("", "NA", "#DIV/0!"))
test <- read.csv("./test.csv", na.strings = c("", "NA", "#DIV/0!"))
## Build our model
## First create the training set
table(train$classe)
set.seed(999)
inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
training <- train[inTrain,]
testing <- train[-inTrain,]
## Now remove features that are not likely to contribute to the model using the nearZeroVar function
nsv <- nearZeroVar(training)
training <- training[, -nsv]
training <- select(training, -(X:num_window))
training<-training[,colSums(is.na(training))/nrow(training) < 0.50]
## Train the model using Random Forest
RFmodel <- randomForest(classe~., data = training, method = "class")
## Cross validate the model to determine accuracy
myPredict <- predict(RFmodel, testing, type = "class")
confusionMatrix(myPredict, testing$classe)
## Run our predictions for the supplied test set
pResults <- predict(RFmodel, test, type = "class")
pResults
## Write out our prediction files for submission
n = length(pResults)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
setwd("~/Downloads/RegressionModelsProject")
